{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rx3lsyYmxMRj"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyp-F8lMkPTP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OvfqbtFxUZN"
   },
   "source": [
    "## Omnigot Dataset class\n",
    "This class is derived from the Dataset class. It is responsible for downloading, extracting and loading the Omniglot dataset. Also allows getting i-th datapoints and preparing sets for n-way validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-C_Ke16vwAH"
   },
   "outputs": [],
   "source": [
    "class Omniglot(Dataset):\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the Omniglot dataset. Downloads, extracts and loads the data in memory\"\"\"\n",
    "        super(Omniglot, self).__init__()\n",
    "        np.random.seed(0)\n",
    "\n",
    "        self.__acquire_dataset()\n",
    "        self.transform = transforms.Compose([transforms.RandomAffine(15), transforms.ToTensor()])\n",
    "        self.data = self.__load_data()\n",
    "        print(\"Dataset loaded in memory!\")\n",
    "\n",
    "    def __download_dataset(self):\n",
    "        \"\"\" Downloads the Omniglot dataset\"\"\"\n",
    "        print(\"Downloading the Omniglot dataset...\")\n",
    "        os.system('wget https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip')\n",
    "        os.system('wget https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip')\n",
    "\n",
    "    def __extract_dataset(self):\n",
    "        \"\"\" Extracts the Omniglot dataset\"\"\"\n",
    "        print(\"Extracting the Omniglot dataset...\")\n",
    "        os.system('unzip images_background')\n",
    "        os.system('unzip images_evaluation')\n",
    "\n",
    "    def __acquire_dataset(self):\n",
    "        \"\"\" Downloads and extracts the Omniglot dataset\"\"\"\n",
    "        print(\"Acquiring the Omniglot dataset...\")\n",
    "\n",
    "        if os.path.exists('/content/images_background'):\n",
    "            print(\"Dataset downloaded and extracted!\")\n",
    "            return\n",
    "\n",
    "        if os.path.isfile('/content/images_background.zip'):\n",
    "            self.__extract_dataset()\n",
    "        else:\n",
    "            self.__download_dataset()\n",
    "            self.__extract_dataset()           \n",
    "\n",
    "        print(\"Dataset downloaded and extracted!\")\n",
    "\n",
    "    def __load_data(self):\n",
    "        print(\"Loading the dataset in memory...\")\n",
    "        data_path = '/content/images_background/'\n",
    "        data = {}\n",
    "\n",
    "        for alphabet in os.listdir(data_path):\n",
    "            data[alphabet] = {}\n",
    "            alpha_path = os.path.join(data_path, alphabet)\n",
    "\n",
    "            for character in os.listdir(alpha_path):\n",
    "                imgs = []\n",
    "                img_path = os.path.join(data_path, alphabet, character)\n",
    "                for img in os.listdir(img_path):\n",
    "                    img_path = os.path.join(data_path, alphabet, character, img)\n",
    "                    imgs.append(Image.open(img_path).convert('L'))\n",
    "                \n",
    "                data[alphabet][character] = imgs\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for alphabet in self.data:\n",
    "            for character in self.data[alphabet]:\n",
    "                for img in character:\n",
    "                    length += 1\n",
    "        return length      \n",
    "    \n",
    "    def get_num_classes(self):\n",
    "        count = 0\n",
    "        for alphabet in self.data:\n",
    "            for character in self.data[alphabet]:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = None\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "\n",
    "        alphabets = list(self.data.keys())\n",
    "\n",
    "        if index % 2 == 0:\n",
    "            target = torch.from_numpy(np.array([1.0], dtype=np.float32))\n",
    "            alphabet = random.choice(alphabets)\n",
    "            characters = list(self.data[alphabet].keys())\n",
    "            character = random.choice(characters)\n",
    "            imgs = self.data[alphabet][character]\n",
    "\n",
    "            img1 = random.choice(imgs)\n",
    "            img2 = random.choice(imgs)\n",
    "\n",
    "        else:\n",
    "            target = torch.from_numpy(np.array([0.0], dtype=np.float32))\n",
    "\n",
    "            alphabet_1 = random.choice(alphabets)\n",
    "            alphabet_2 = random.choice(alphabets)\n",
    "\n",
    "            while alphabet_1 == alphabet_2:\n",
    "                alphabet_2 = random.choice(alphabets)\n",
    "            \n",
    "            characters_1 = list(self.data[alphabet_1].keys())\n",
    "            characters_2 = list(self.data[alphabet_2].keys())\n",
    "            char1 = random.choice(characters_1)\n",
    "            char2 = random.choice(characters_2)\n",
    "\n",
    "            img1 = random.choice(self.data[alphabet_1][char1])\n",
    "            img2 = random.choice(self.data[alphabet_2][char2])\n",
    "\n",
    "        img1 = self.transform(img1)\n",
    "        img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, target\n",
    "\n",
    "    # Functions for validation\n",
    "    def make_n_way_sets(self, n=3):\n",
    "        \"\"\" Prepares lists of images for n-way validation\n",
    "            Takes: n (int) as arugment\n",
    "            Returns: a list of lists containing n+1 images, with the first two images belonging to the same class,\n",
    "                        while the remaining n-2 images are from random classes\n",
    "                    The targets for similarity should be 1 for the 2nd image, and 0 for the rest (1st image is the image being validated)\"\"\"\n",
    "        images = []\n",
    "\n",
    "        for alphabet in self.data:\n",
    "            for character in self.data[alphabet]:\n",
    "                current_image = random.choice(self.data[alphabet][character])\n",
    "\n",
    "                other_image = current_image\n",
    "                while other_image == current_image:\n",
    "                    other_image = random.choice(self.data[alphabet][character])\n",
    "\n",
    "                current_image_set = []\n",
    "\n",
    "                current_image_set.append(current_image)\n",
    "                current_image_set.append(other_image)\n",
    "\n",
    "                for i in range(n - 1):\n",
    "                    random_alphabet = random.choice(list(self.data))\n",
    "                    random_character = random.choice(list(self.data[random_alphabet])) \n",
    "\n",
    "                    while random_alphabet == language and random_character == character:\n",
    "                        random_character =  random.choice(list(self.data[random_alphabet]))\n",
    "\n",
    "                    random_image = random.choice(self.data[random_alphabet][random_character])\n",
    "                    current_image_set.append(random_image)\n",
    "\n",
    "                images.append(current_image_set)\n",
    "\n",
    "        return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftoFSeauxo5S"
   },
   "source": [
    "## Siamese Neural Network\n",
    "This class defines the architecture of the Siamese Network used for One-Shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWoFfLW5gJ19"
   },
   "outputs": [],
   "source": [
    "class Siamese_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Siamese_Net, self).__init__()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=10),  \n",
    "            nn.ReLU(inplace=True),\n",
    "   \n",
    "            nn.MaxPool2d(kernel_size=2),  \n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=7),\n",
    "            nn.ReLU(),   \n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2),  \n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4),\n",
    "            nn.ReLU(), \n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2), \n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4),\n",
    "            nn.ReLU(),  \n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(9216, 4096), nn.Sigmoid())\n",
    "        self.output = nn.Linear(4096, 1)\n",
    "\n",
    "    def forward_pass(self, inp):\n",
    "        inp = self.conv_block(inp)\n",
    "        inp = inp.view(inp.size()[0], -1)\n",
    "        inp = self.linear(inp)\n",
    "        return inp\n",
    "\n",
    "    def forward(self, inp1, inp2):\n",
    "        pass_1 = self.forward_pass(inp1)\n",
    "        pass_2 = self.forward_pass(inp2)\n",
    "        output = self.output(torch.abs(pass_1 - pass_2))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5tYWRWf0qHZ"
   },
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IWg_K7gKgqdt"
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X59Wtm5focxG"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 2\n",
    "\n",
    "train_dataset = Omniglot()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jp8gj4IugtU3"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIXs7EIl3wyq"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss(size_average=True)\n",
    "model = Siamese_Net()\n",
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00006)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for epoch in range(100):\n",
    "    run_loss = 0.0\n",
    "    print (\"Epoch: \", epoch)\n",
    "    for batch_id, (img1, img2, label) in enumerate(train_loader, 1):\n",
    "        img1, img2, label = Variable(img1.cuda()), Variable(img2.cuda()), Variable(label.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(img1, img2)\n",
    "        loss = criterion(output, label)\n",
    "        run_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id % 10 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, batch_id + 1, run_loss))\n",
    "            run_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHKmC9lfQ_Ce"
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"trained_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
