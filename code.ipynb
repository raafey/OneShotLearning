{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IrEEhorwQlS"
   },
   "source": [
    "### Paper Implemented: Siamese Neural Networks for One-Shot Image Recognition\n"
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rx3lsyYmxMRj"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyp-F8lMkPTP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OvfqbtFxUZN"
   },
   "source": [
    "## Omnigot Dataset class\n",
    "This class is derived from the Dataset class. It is responsible for downloading, extracting and loading the Omniglot dataset. Also allows getting i-th datapoints and preparing sets for n-way validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-C_Ke16vwAH"
   },
   "outputs": [],
   "source": [
    "class Omniglot(Dataset):\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the Omniglot dataset. Downloads, extracts and loads the data in memory\"\"\"\n",
    "        super(Omniglot, self).__init__()\n",
    "        np.random.seed(0)\n",
    "\n",
    "        self.__acquire_dataset()\n",
    "        self.transform = transforms.Compose([transforms.RandomAffine(15), transforms.ToTensor()])\n",
    "        self.data = self.__load_data()\n",
    "        print(\"Dataset loaded in memory!\")\n",
    "\n",
    "    def __download_dataset(self):\n",
    "        \"\"\" Downloads the Omniglot dataset\"\"\"\n",
    "        print(\"Downloading the Omniglot dataset...\")\n",
    "        os.system('wget https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip')\n",
    "        os.system('wget https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip')\n",
    "\n",
    "    def __extract_dataset(self):\n",
    "        \"\"\" Extracts the Omniglot dataset\"\"\"\n",
    "        print(\"Extracting the Omniglot dataset...\")\n",
    "        os.system('unzip images_background')\n",
    "        os.system('unzip images_evaluation')\n",
    "\n",
    "    def __acquire_dataset(self):\n",
    "        \"\"\" Downloads and extracts the Omniglot dataset\"\"\"\n",
    "        print(\"Acquiring the Omniglot dataset...\")\n",
    "\n",
    "        if os.path.exists('/content/images_background'):\n",
    "            print(\"Dataset downloaded and extracted!\")\n",
    "            return\n",
    "\n",
    "        if os.path.isfile('/content/images_background.zip'):\n",
    "            self.__extract_dataset()\n",
    "        else:\n",
    "            self.__download_dataset()\n",
    "            self.__extract_dataset()           \n",
    "\n",
    "        print(\"Dataset downloaded and extracted!\")\n",
    "\n",
    "    def __load_data(self):\n",
    "        print(\"Loading the dataset in memory...\")\n",
    "        data_path = '/content/images_background/'\n",
    "        data = {}\n",
    "\n",
    "        for alphabet in os.listdir(data_path):\n",
    "            data[alphabet] = {}\n",
    "            alpha_path = os.path.join(data_path, alphabet)\n",
    "\n",
    "            for character in os.listdir(alpha_path):\n",
    "                imgs = []\n",
    "                img_path = os.path.join(data_path, alphabet, character)\n",
    "                for img in os.listdir(img_path):\n",
    "                    img_path = os.path.join(data_path, alphabet, character, img)\n",
    "                    imgs.append(Image.open(img_path).convert('L'))\n",
    "                \n",
    "                data[alphabet][character] = imgs\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for alphabet in self.data:\n",
    "            for character in self.data[alphabet]:\n",
    "                for img in character:\n",
    "                    length += 1\n",
    "        return length      \n",
    "    \n",
    "    def get_num_classes(self):\n",
    "        count = 0\n",
    "        for alphabet in self.data:\n",
    "            for character in self.data[alphabet]:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = None\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "\n",
    "        alphabets = list(self.data.keys())\n",
    "\n",
    "        if index % 2 == 0:\n",
    "            target = torch.from_numpy(np.array([1.0], dtype=np.float32))\n",
    "            alphabet = random.choice(alphabets)\n",
    "            characters = list(self.data[alphabet].keys())\n",
    "            character = random.choice(characters)\n",
    "            imgs = self.data[alphabet][character]\n",
    "\n",
    "            img1 = random.choice(imgs)\n",
    "            img2 = random.choice(imgs)\n",
    "\n",
    "        else:\n",
    "            target = torch.from_numpy(np.array([0.0], dtype=np.float32))\n",
    "\n",
    "            alphabet_1 = random.choice(alphabets)\n",
    "            alphabet_2 = random.choice(alphabets)\n",
    "\n",
    "            while alphabet_1 == alphabet_2:\n",
    "                alphabet_2 = random.choice(alphabets)\n",
    "            \n",
    "            characters_1 = list(self.data[alphabet_1].keys())\n",
    "            characters_2 = list(self.data[alphabet_2].keys())\n",
    "            char1 = random.choice(characters_1)\n",
    "            char2 = random.choice(characters_2)\n",
    "\n",
    "            img1 = random.choice(self.data[alphabet_1][char1])\n",
    "            img2 = random.choice(self.data[alphabet_2][char2])\n",
    "\n",
    "        img1 = self.transform(img1)\n",
    "        img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, target\n",
    "\n",
    "    # Functions for validation\n",
    "    def make_n_way_sets(self, n=3):\n",
    "        \"\"\" Prepares lists of images for n-way validation\n",
    "            Takes: n (int) as arugment\n",
    "            Returns: a list of lists containing n+1 images, with the first two images belonging to the same class,\n",
    "                        while the remaining n-2 images are from random classes\n",
    "                    The targets for similarity should be 1 for the 2nd image, and 0 for the rest (1st image is the image being validated)\"\"\"\n",
    "        images = []\n",
    "\n",
    "        for alphabet in self.data:\n",
    "            for character in self.data[alphabet]:\n",
    "                current_image = random.choice(self.data[alphabet][character])\n",
    "\n",
    "                other_image = current_image\n",
    "                while other_image == current_image:\n",
    "                    other_image = random.choice(self.data[alphabet][character])\n",
    "\n",
    "                current_image_set = []\n",
    "\n",
    "                current_image_set.append(current_image)\n",
    "                current_image_set.append(other_image)\n",
    "\n",
    "                for i in range(n - 1):\n",
    "                    random_alphabet = random.choice(list(self.data))\n",
    "                    random_character = random.choice(list(self.data[random_alphabet])) \n",
    "\n",
    "                    while random_alphabet == language and random_character == character:\n",
    "                        random_character =  random.choice(list(self.data[random_alphabet]))\n",
    "\n",
    "                    random_image = random.choice(self.data[random_alphabet][random_character])\n",
    "                    current_image_set.append(random_image)\n",
    "\n",
    "                images.append(current_image_set)\n",
    "\n",
    "        return images\n",
    "\n",
    "    # The function below needs to be rewritten for our implementation\n",
    "\n",
    "    # def test_oneshot(model, N, k, s = \"val\", verbose = 0):\n",
    "    # \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "    #     n_correct = 0\n",
    "    #     if verbose:\n",
    "    #         print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "    #     for i in range(k):\n",
    "    #         inputs, targets = make_oneshot_task(N,s)\n",
    "    #         probs = model.predict(inputs)\n",
    "    #         if np.argmax(probs) == np.argmax(targets):\n",
    "    #             n_correct+=1\n",
    "    #     percent_correct = (100.0 * n_correct / k)\n",
    "    #     if verbose:\n",
    "    #         print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "    #     return percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftoFSeauxo5S"
   },
   "source": [
    "## Siamese Neural Network\n",
    "This class defines the architecture of the Siamese Network used for One-Shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWoFfLW5gJ19"
   },
   "outputs": [],
   "source": [
    "class Siamese_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Siamese_Net, self).__init__()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=10),  \n",
    "            nn.ReLU(inplace=True),\n",
    "   \n",
    "            nn.MaxPool2d(kernel_size=2),  \n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=7),\n",
    "            nn.ReLU(),   \n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2),  \n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4),\n",
    "            nn.ReLU(), \n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2), \n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4),\n",
    "            nn.ReLU(),  \n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(9216, 4096), nn.Sigmoid())\n",
    "        self.output = nn.Linear(4096, 1)\n",
    "\n",
    "    def forward_pass(self, inp):\n",
    "        inp = self.conv_block(inp)\n",
    "        inp = inp.view(inp.size()[0], -1)\n",
    "        inp = self.linear(inp)\n",
    "        return inp\n",
    "\n",
    "    def forward(self, inp1, inp2):\n",
    "        pass_1 = self.forward_pass(inp1)\n",
    "        pass_2 = self.forward_pass(inp2)\n",
    "        output = self.output(torch.abs(pass_1 - pass_2))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5tYWRWf0qHZ"
   },
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IWg_K7gKgqdt"
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X59Wtm5focxG"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_workers = 2\n",
    "\n",
    "train_dataset = Omniglot()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jp8gj4IugtU3"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIXs7EIl3wyq"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss(size_average=True)\n",
    "model = Siamese_Net()\n",
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00006)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "for epoch in range(100):\n",
    "    run_loss = 0.0\n",
    "    print (\"Epoch: \", epoch)\n",
    "    for batch_id, (img1, img2, label) in enumerate(train_loader, 1):\n",
    "        img1, img2, label = Variable(img1.cuda()), Variable(img2.cuda()), Variable(label.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(img1, img2)\n",
    "        loss = criterion(output, label)\n",
    "        run_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id % 10 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, batch_id + 1, run_loss))\n",
    "            run_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHKmC9lfQ_Ce"
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"trained_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfWhN0OnjVD7"
   },
   "source": [
    "## Testing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLoNiciAoHzP"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-57273bfc2ca2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trained_model.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mroot_key\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 deserialized_objects[root_key] = restore_location(\n\u001b[1;32m--> 505\u001b[1;33m                     data_type(size), location)\n\u001b[0m\u001b[0;32m    506\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[0;32m     80\u001b[0m                            \u001b[1;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                            \u001b[1;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "model = torch.load(\"trained_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
